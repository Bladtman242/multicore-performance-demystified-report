\chapter{Abstract}
With this report, I provide further evidence that false sharing of cache lines
can significantly harm the performance of practical multicore software running
on managed platforms. I describe the mechanisms of hardware caches that cause
false sharing overhead, and relate them to Java's concurrency constructs. I
describe techniques to manipulate the memory layout in Java programs and improve
multicore cache performance, all within the programming model afforded to us by
Java. I verify by experiment that these techniques work, and that the
performance impact they have can be considerable.

\chapter{Introduction}
As software systems grow more complex, the tools and models we use to design
them grow more abstract. It seems that the more software designers wish to
accomplish in a single project, the further we move away from the bare metal of
modern hardware.

High-level programming languages like Java, F\#, and even C hide the
mind-boggling complexities of the hardware our programs run on, in favour of
simpler abstractions that make it easier (or even feasible) to design and
understand complex software systems. Even with low-level languages, entire
hardware components are abstracted away: In the x86-64 instruction set for
example, the CPU cache is essentially invisible to the programmer except for a
few prefetch instructions. 
To see the scale of
complexity we are talking about, consider that Intel's first i3, i5, and i7
architectures had 810 million transistors, almost three times as many as their
Core 2 duo processors from just 2 years earlier \cite{plc}. Present-day
commodity Intel architectures have transistor counts in the billions. With
respect to both physical memory layout and discrete logic circuitry, that is a
lot of hardware that we do not want to have to worry about the details of.
If we accept the adage that "the purpose of abstracting is not to be vague, but
to create a new semantic level in which one can be absolutely
precise"\cite{dijkstra}, it is easy to appreciate the work of those who hide
away the complexities of computer hardware, allowing us to focus on more
high-level problems in our software design.

However, such abstractions can betray the unsuspecting software designer, whose
understanding of the hardware they use is clouded by the abstractions they use
it through.

In \textit{A multicore performance mystery solved}\cite{mystery},
\citeauthor{mystery} brings to attention an example of such a betrayal: The
curious performance impact caused by false sharing of CPU cache-lines. Using a
k-means clustering implementation as example, he shows how a seemingly obvious
optimization makes the program 7.7 times slower in practice.

The aim of this report is to demystify multicore performance and help eliminate
false sharing overhead. We achieve this through mechanical sympathy. We see that
cache-friendly design in multicore programming is radically different from
cache-friendly design in single-core programming. Having learned about cache
coherence protocols, we try to bridge the gap between how we think about memory
hardware, and how we think about memory in Java. Finally, we perform experiments
with 6 different multicore programs on three different platforms to reinforce our
understanding of multicore performance in Java.

The intended audience is the graduate- or post-graduate level software designer
who is used to working on high-level, managed platforms (such as Java), and who
is unaccustomed to considerations of low-level hardware details, such as cache
coherence.

\chapter{How to read this report}
It is fair to say this report has more breadth than depth. The following
paragraphs should aid readers in deciding which chapters are relevant to them.

Readers wishing to understand the workings and impact of false sharing should
read section \ref{sec:caches}. Readers who wish to learn techniques for avoiding
false sharing overhead in java should read chapter \ref{chap:javamem}. Readers
wish to see evidence of the performance characteristics of data sharing between
CPUs should read the experiments in chapter \ref{chap:experiments}. Readers who
are interested only in evidence that false sharing has a performance impact may
wish to skip most of the chapter, and focus on the uncontended- and contended-
writes problems, as well as the k-means problem or the histogram problem for
more practical examples.

The following outlines the chapters of this report:\\
Chapter \ref{chap:arch} provides a naive description of the memory hierarchy at
large. Section \ref{sec:caches} goes deeper into detail with CPU
caches, and ends with a description of false sharing of cache lines, based on
the MESI cache coherence protocol.

Chapter \ref{chap:background} summarizes previous work and relevant literature
on false sharing, hardware design, and multicore software design in general.

Chapter \ref{chap:javamem} explains how hardware cache coherence relates to the
Java memory model, and ends by suggesting an array of techniques for
manipulating the memory layout of java programs -- something Java provides
little to no support for.

Chapter \ref{chap:busyness} underlines the importance of memory operations in
regards to program performance, and elaborates on the differences in cache-friendly
design in single- and multi-core software.

Chapter \ref{chap:method} describes the experimental setup and limitations of the
experiments in chapter \ref{chap:experiments}.

Chapter \ref{chap:experiments} details multicore-performance experiments with 4
practical problems and two more contrived examples illustrating false sharing of
cache lines.

Finally, chapter \ref{chap:advice} summarizes the lessons of this project, in
the form of a bit of advice to multicore programmers.
